Model,MMLU,B Params
Llama 3.2 1B,49.30%,1
Apple OpenElm 1.1B,27.10%,1.1
Llama 3.2 3B,63.40%,3
Mistral 7B,62.50%,7
AppleOpenElm 3B,26.80%,3
Llama 3.1 8B,69.40%,8
Qwen2.5-32b,83.30%,32
Llama 3 8B,66.60%,8
Gemma 8B,64.40%,8
Gemma 2 9B,71.30%,9
Llama-3.2-11B,73.00%,11
Llama 2 Chat 7B,45.80%,7
Llama 2 Chat 13B,53.60%,13
Gemma 2 27B,75.20%,27
DBRX,74.70%,36
Mixtral Large Base,71.90%,39
Llama 3.1 70B,86.00%,70
Qwen2.5 72B,86.10%,72
Llama-3.1-Nemotron-70B-Instruct-HF,83.50%,70
Qwen2 72B,84.20%,72
NVLM-D-72B,82.00%,72
Llama 3 70B,79.50%,70
Claude 3 Sonnet,79.00%,70
LLaMA2-70B Base,69.80%,70
QwQ-32B,78.20%,32
Gemma-3-27B,64.90%,27
R1-32B,73.90%,32
Deepseek-R1,90.80%,671
DeepSeek-v2,78.40%,21
Deepseek-v3,87.10%,37
Llama-3.2-90B,86.00%,90
GPT-3.5,70.00%,167
Grok-1,73.00%,314
Nemotron-4-340B-Instruct,78.70%,340
QWQ-32B,76.40%,32
Qwen 3-235B,87.80%,238
Qwen3-4B,69.50%,4
Qwen3-8B,74.70%,8
Qwen3-14B,78.50%,14
Qwen3-32B,89.80%,32
Llama 3 405B,85.20%,405
Gemini Ultra,90.00%,1560
GPT-04-mini,81.60%,1800
GPT-o3,82.90%,1800
GPT-4o,88.70%,1800
GPT-4,86.40%,1800
Claude 3 Opus,86.80%,2000
Qwen3-235B,89.20%,235
