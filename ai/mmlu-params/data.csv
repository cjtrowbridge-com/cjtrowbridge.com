Model,MMLU,B Params,Citation
Llama 3.2 1B,49.30%,1,https://huggingface.co/meta-llama/Llama-3.2-1B#:~:text=Capability%20Benchmark%20
Apple OpenElm 1.1B,27.10%,1.1,https://huggingface.co/apple/OpenELM#:~:text=OpenELM
Llama 3.2 3B,63.40%,3,https://huggingface.co/meta-llama/Llama-3.2-1B#:~:text=Capability%20Benchmark%20
Mistral 7B,62.50%,7,https://developers.googleblog.com/en/introducing-gemma-models-in-keras/#:~:text=Gemma%20models%20come%20in%20portable
AppleOpenElm 3B,26.80%,3,https://huggingface.co/apple/OpenELM#:~:text=OpenELM
Llama 3.1 8B,69.40%,8,https://console.groq.com/docs/model/llama-3.1-8b-instant#:~:text=Performance%20Metrics
Qwen2.5-32b,83.30%,32,
Llama 3 8B,66.60%,8,https://huggingface.co/meta-llama/Meta-Llama-3-8B#:~:text=Base%20pretrained%20models
Gemma 8B,64.40%,8,https://predibase.com/blog/how-to-efficiently-fine-tune-gemma-7b-with-open-source-ludwig#:~:text=for%20their%20sizes%2C%20compared%20to
Gemma 2 9B,71.30%,9,https://console.groq.com/docs/model/gemma2-9b-it#:~:text=Performance%20Metrics
Llama-3.2-11B,73.00%,11,https://www.prompthackers.co/compare/llama-3.2-11b/llama-3.2-3b#:~:text=Discover%20how%20Meta%27s%20Llama%203
Llama 2 Chat 7B,45.80%,7,https://openlaboratory.ai/models/llama-2-7b#:~:text=Llama%202%207B%20exhibits%20enhanced
Llama 2 Chat 13B,53.60%,13,https://openlaboratory.ai/models/llama-2-13b#:~:text=Evaluation%20and%20Benchmark%20Performance
Gemma 2 27B,75.20%,27,https://openlaboratory.ai/models/gemma-2-9b#:~:text=Evaluations%20have%20placed%20Gemma%202
DBRX,74.70%,36,https://www.chaosgenius.io/blog/dbrx/#:~:text=1
Mixtral Large Base,71.90%,39,https://www.chaosgenius.io/blog/dbrx/#:~:text=1
Llama 3.1 70B,86.00%,70,https://blog.promptlayer.com/meta-model-analysis-llama-3-vs-3-1/#:~:text=Evaluation%20Category%20Llama%203
Qwen2.5 72B,86.10%,72,https://hub.researchgraph.org/qwen-2-5-is-it-really-that-good/#:~:text=In%20terms%20of%20benchmarking%2C%20Qwen2
Llama-3.1-Nemotron-70B-Instruct-HF,83.50%,70,https://huggingface.co/RedHatAI/Llama-3.1-Nemotron-70B-Instruct-HF-FP8-dynamic#:~:text=OpenLLM%20v1%20MMLU%20%285
Qwen2 72B,84.20%,72,https://huggingface.co/Qwen/Qwen2-72B#:~:text=Params%20236B%20140B%2070B%2072B
NVLM-D-72B,82.00%,72,https://huggingface.co/nvidia/NVLM-D-72B#:~:text=Gemini%201
Llama 3 70B,79.50%,70,https://huggingface.co/meta-llama/Meta-Llama-3-8B#:~:text=Base%20pretrained%20models
Claude 3 Sonnet,79.00%,70,
LLaMA2-70B Base,69.80%,70,https://github.com/meta-llama/llama-models/blob/main/models/llama2/MODEL_CARD.md#:~:text=Model%20Size%20Code%20Commonsense%20Reasoning
QwQ-32B,78.20%,32,
Gemma-3-27B,64.90%,27,
R1-32B,73.90%,32,
Deepseek-R1,90.80%,671,https://blog.promptlayer.com/deepseek-v3-vs-r1/#:~:text=DeepSeek%20R1%20focuses%20on%20logical
DeepSeek-v2,78.40%,21,
Deepseek-v3,87.10%,37,https://blog.promptlayer.com/deepseek-v3-vs-r1/#:~:text=Metric%20DeepSeek%20V3%20DeepSeek%20R1
Llama-3.2-90B,86.00%,90,https://ai.azure.com/catalog/models/Llama-3.2-90B-Vision-Instruct#:~:text=Text%20General%20MMLU%20
GPT-3.5,70.00%,167,https://www.chaosgenius.io/blog/dbrx/#:~:text=1
Grok-1,73.00%,314,https://www.chaosgenius.io/blog/dbrx/#:~:text=1
Nemotron-4-340B-Instruct,78.70%,340,
QWQ-32B,76.40%,32,
Qwen 3-235B,87.80%,238,
Qwen3-0.6B,52.81%,0.6,https://arxiv.org/abs/2505.09388
Qwen3-1.7B,62.63%,1.7,https://arxiv.org/abs/2505.09388
Qwen3-4B,69.50%,4,
Qwen3-8B,74.70%,8,
Qwen3-14B,78.50%,14,
Qwen3-32B,89.80%,32,
Llama 3 405B,85.20%,405,
Gemini Ultra,90.00%,1560,https://galileo.ai/blog/mmlu-benchmark#:~:text=Current%20MMLU%20Leaderboard%20and%20Performance
GPT-04-mini,81.60%,1800,
GPT-o3,82.90%,1800,
GPT-4o,88.70%,1800,
GPT-4,86.40%,1800,https://galileo.ai/blog/mmlu-benchmark#:~:text=Current%20MMLU%20Leaderboard%20and%20Performance
Claude 3 Opus,86.80%,2000,
Qwen3-235B,89.20%,235,
GOT-OSS-20B,73.60%,20,
GPT-OSS-120B,79.30%,120,
